apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  annotations:
    pipelines.kubeflow.org/kfp_sdk_version: 1.8.19
    pipelines.kubeflow.org/pipeline_compilation_time: '2023-03-14T10:07:51.451157'
    pipelines.kubeflow.org/pipeline_spec: '{"description": "Tiny pipeline that includes
      a single component to upload a HF dataset to the cloud", "inputs": [{"default":
      "lambdalabs/pokemon-blip-captions", "name": "dataset_name", "optional": true}],
      "name": "HF Dataset tiny pipeline"}'
  generateName: hf-dataset-tiny-pipeline-
  labels:
    pipelines.kubeflow.org/kfp_sdk_version: 1.8.19
spec:
  arguments:
    parameters:
    - name: dataset_name
      value: lambdalabs/pokemon-blip-captions
  entrypoint: hf-dataset-tiny-pipeline
  serviceAccountName: pipeline-runner
  templates:
  - dag:
      tasks:
      - arguments:
          parameters:
          - name: dataset_name
            value: '{{inputs.parameters.dataset_name}}'
        name: load-from-hub
        template: load-from-hub
    inputs:
      parameters:
      - name: dataset_name
    name: hf-dataset-tiny-pipeline
  - container:
      args: []
      command:
      - python3
      - main.py
      - --dataset_name
      - '{{inputs.parameters.dataset_name}}'
      image: europe-west4-docker.pkg.dev/soy-audio-379412/soy-audio-379412-default-repository/kubeflow-components/components/example_component:latest
      imagePullPolicy: Always
    inputs:
      parameters:
      - name: dataset_name
    metadata:
      annotations:
        pipelines.kubeflow.org/arguments.parameters: '{"dataset_name": "{{inputs.parameters.dataset_name}}"}'
        pipelines.kubeflow.org/component_ref: '{"digest": "27890612ee9f47f0203ce706896bef3e61b04e0f791bd4ffe836135b91bc2e06",
          "url": "/Users/nielsrogge/Documents/python_projects/express/examples/pipelines/hf_dataset_pipeline/components/load_from_hub/component.yaml"}'
        pipelines.kubeflow.org/component_spec: '{"description": "A basic component
          that takes a dataset name from the \ud83e\udd17 hub as input and uploads
          it to a GCS bucket.", "implementation": {"container": {"command": ["python3",
          "main.py", "--dataset_name", {"inputValue": "dataset_name"}], "image": "europe-west4-docker.pkg.dev/soy-audio-379412/soy-audio-379412-default-repository/kubeflow-components/components/example_component:latest"}},
          "inputs": [{"description": "Name of the HF Dataset from the \ud83e\udd17
          hub", "name": "dataset_name", "type": "String"}], "name": "load_from_hub",
          "outputs": [{"description": "Path to the local file containing the gcs path
          where the output has been stored", "name": "data_manifest_path"}]}'
        pipelines.kubeflow.org/task_display_name: HF Dataset loader component
      labels:
        pipelines.kubeflow.org/enable_caching: 'true'
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.19
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
    name: load-from-hub
    outputs:
      artifacts:
      - name: load-from-hub-data_manifest_path
        path: /tmp/outputs/data_manifest_path/data
